{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Employee Turnover Analytics - Course-end Project 1\n",
        "**Simplilearn AI & ML PGP | Portobello Tech HR Dataset**\n",
        "\n",
        "This notebook covers:\n",
        "1. Data quality checks (missing values)\n",
        "2. EDA - factors contributing to employee turnover\n",
        "3. Clustering of employees who left (satisfaction & evaluation)\n",
        "4. Class imbalance handling with SMOTE\n",
        "5. K-fold cross-validation model training and evaluation\n",
        "6. Best model selection with justified metrics\n",
        "7. Retention strategies for targeted employees"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,\n",
        "                             roc_auc_score, classification_report, confusion_matrix)\n",
        "from sklearn.cluster import KMeans\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "%matplotlib inline\n",
        "sns.set_style('whitegrid')\n",
        "print(\"Libraries loaded successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load Data & Data Quality Checks\n",
        "Load HR dataset and check for missing values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load dataset (use path relative to notebook location)\n",
        "df = pd.read_csv('HR_comma_sep.csv')\n",
        "print(\"Dataset shape:\", df.shape)\n",
        "print(\"\\nFirst 5 rows:\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data quality checks - Missing values\n",
        "print(\"=== DATA QUALITY CHECKS ===\\n\")\n",
        "print(\"Missing values per column:\")\n",
        "print(df.isnull().sum())\n",
        "print(\"\\nTotal missing values:\", df.isnull().sum().sum())\n",
        "print(\"\\nData types:\\n\", df.dtypes)\n",
        "print(\"\\nBasic statistics:\")\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Class distribution (target: left)\n",
        "print(\"Target 'left' distribution:\")\n",
        "print(df['left'].value_counts())\n",
        "print(\"\\nPercentage:\")\n",
        "print(df['left'].value_counts(normalize=True).round(3) * 100)\n",
        "sns.countplot(data=df, x='left')\n",
        "plt.title('Employee Turnover (0=Stayed, 1=Left)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Exploratory Data Analysis - Factors Contributing to Turnover\n",
        "Understand which factors contribute most to employee turnover."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Correlation with target\n",
        "df_numeric = df.select_dtypes(include=[np.number])\n",
        "corr_with_left = df_numeric.corr()['left'].drop('left').sort_values(key=abs, ascending=False)\n",
        "print(\"Correlation with 'left' (absolute):\\n\", corr_with_left)\n",
        "corr_with_left.plot(kind='barh', figsize=(8,4))\n",
        "plt.title('Feature correlation with Employee Turnover')\n",
        "plt.xlabel('Correlation')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Turnover rate by categorical features\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
        "df.groupby('salary')['left'].mean().plot(kind='bar', ax=axes[0], color='steelblue')\n",
        "axes[0].set_title('Turnover rate by Salary')\n",
        "axes[0].set_ylabel('Turnover rate')\n",
        "axes[0].tick_params(axis='x', rotation=45)\n",
        "df.groupby('sales')['left'].mean().plot(kind='bar', ax=axes[1], color='coral')\n",
        "axes[1].set_title('Turnover rate by Department (sales)')\n",
        "axes[1].set_ylabel('Turnover rate')\n",
        "axes[1].tick_params(axis='x', rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Key numeric factors: satisfaction_level, time_spend_company, number_project\n",
        "fig, axes = plt.subplots(2, 2, figsize=(10, 8))\n",
        "sns.boxplot(data=df, x='left', y='satisfaction_level', ax=axes[0,0])\n",
        "axes[0,0].set_title('Satisfaction vs Left')\n",
        "sns.boxplot(data=df, x='left', y='time_spend_company', ax=axes[0,1])\n",
        "axes[0,1].set_title('Tenure vs Left')\n",
        "sns.boxplot(data=df, x='left', y='number_project', ax=axes[1,0])\n",
        "axes[1,0].set_title('Number of projects vs Left')\n",
        "sns.boxplot(data=df, x='left', y='average_montly_hours', ax=axes[1,1])\n",
        "axes[1,1].set_title('Avg monthly hours vs Left')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "print(\"\\nEDA Summary: Low satisfaction, longer tenure, high hours and project count associate with higher turnover.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Clustering of Employees Who Left (Satisfaction & Evaluation)\n",
        "Cluster employees who left based on satisfaction_level and last_evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Subset: employees who left\n",
        "df_left = df[df['left'] == 1][['satisfaction_level', 'last_evaluation']].copy()\n",
        "# Elbow method for optimal k\n",
        "inertias = []\n",
        "K = range(2, 8)\n",
        "for k in K:\n",
        "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
        "    kmeans.fit(df_left)\n",
        "    inertias.append(kmeans.inertia_)\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(K, inertias, 'bo-')\n",
        "plt.xlabel('Number of clusters (k)')\n",
        "plt.ylabel('Inertia')\n",
        "plt.title('Elbow method for employees who left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# K-Means clustering with k=3 (typical elbow around 3)\n",
        "kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)\n",
        "df_left['cluster'] = kmeans.fit_predict(df_left)\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.scatterplot(data=df_left, x='satisfaction_level', y='last_evaluation', hue='cluster', palette='Set1')\n",
        "plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s=200, c='black', marker='X', label='Centroids')\n",
        "plt.title('Clustering of employees who left (Satisfaction vs Evaluation)')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "print(\"Cluster sizes:\", df_left['cluster'].value_counts().sort_index())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Data Preprocessing & SMOTE for Class Imbalance\n",
        "Encode categoricals, scale features, and apply SMOTE to balance the 'left' class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Encode categorical columns\n",
        "df_ml = df.copy()\n",
        "le_sales = LabelEncoder()\n",
        "le_salary = LabelEncoder()\n",
        "df_ml['sales_enc'] = le_sales.fit_transform(df_ml['sales'])\n",
        "df_ml['salary_enc'] = le_salary.fit_transform(df_ml['salary'])\n",
        "# Features and target\n",
        "feature_cols = ['satisfaction_level', 'last_evaluation', 'number_project', 'average_montly_hours',\n",
        "               'time_spend_company', 'Work_accident', 'promotion_last_5years', 'sales_enc', 'salary_enc']\n",
        "X = df_ml[feature_cols]\n",
        "y = df_ml['left']\n",
        "# Train-test split first (SMOTE only on training set)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "print(\"Before SMOTE - Train:\", y_train.value_counts().to_dict())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "# Apply SMOTE on training data only\n",
        "smote = SMOTE(random_state=42, k_neighbors=5)\n",
        "X_train_bal, y_train_bal = smote.fit_resample(X_train_scaled, y_train)\n",
        "print(\"After SMOTE - Train:\", pd.Series(y_train_bal).value_counts().to_dict())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. K-Fold Cross-Validation & Model Training\n",
        "Train multiple classifiers with stratified k-fold CV and evaluate performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Stratified 5-fold cross-validation\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "models = {\n",
        "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
        "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
        "}\n",
        "cv_results = {}\n",
        "for name, model in models.items():\n",
        "    scores_acc = cross_val_score(model, X_train_bal, y_train_bal, cv=cv, scoring='accuracy')\n",
        "    scores_f1 = cross_val_score(model, X_train_bal, y_train_bal, cv=cv, scoring='f1')\n",
        "    scores_roc = cross_val_score(model, X_train_bal, y_train_bal, cv=cv, scoring='roc_auc')\n",
        "    cv_results[name] = {'accuracy': scores_acc.mean(), 'f1': scores_f1.mean(), 'roc_auc': scores_roc.mean()}\n",
        "    print(f\"{name}: CV Accuracy={scores_acc.mean():.3f}, F1={scores_f1.mean():.3f}, ROC-AUC={scores_roc.mean():.3f}\")\n",
        "cv_df = pd.DataFrame(cv_results).T\n",
        "cv_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train final models on full balanced train set and evaluate on test set (no SMOTE)\n",
        "results = []\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train_bal, y_train_bal)\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "    results.append({\n",
        "        'Model': name,\n",
        "        'Accuracy': accuracy_score(y_test, y_pred),\n",
        "        'Precision': precision_score(y_test, y_pred, zero_division=0),\n",
        "        'Recall': recall_score(y_test, y_pred, zero_division=0),\n",
        "        'F1-Score': f1_score(y_test, y_pred, zero_division=0),\n",
        "        'ROC-AUC': roc_auc_score(y_test, model.predict_proba(X_test_scaled)[:, 1])\n",
        "    })\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Best Model Selection & Evaluation Metrics Justification\n",
        "We use **F1-Score** and **ROC-AUC** as primary metrics because turnover is a class-imbalanced problem: we care about correctly identifying employees who will leave (minority class) without excessive false positives. Accuracy alone can be misleading."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Best model by F1 (and ROC-AUC for robustness)\n",
        "best_by_f1 = results_df.loc[results_df['F1-Score'].idxmax()]\n",
        "print(\"Best model (by F1-Score):\", best_by_f1['Model'])\n",
        "print(best_by_f1)\n",
        "best_model_name = best_by_f1['Model']\n",
        "best_model = models[best_model_name]\n",
        "best_model.fit(X_train_bal, y_train_bal)\n",
        "y_pred_best = best_model.predict(X_test_scaled)\n",
        "print(\"\\nClassification Report (Best Model):\")\n",
        "print(classification_report(y_test, y_pred_best, target_names=['Stayed', 'Left']))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred_best))\n",
        "sns.heatmap(confusion_matrix(y_test, y_pred_best), annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=['Stayed', 'Left'], yticklabels=['Stayed', 'Left'])\n",
        "plt.title(f'Confusion Matrix - {best_model_name}')\n",
        "plt.ylabel('Actual')\n",
        "plt.xlabel('Predicted')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Retention Strategies for Targeted Employees\n",
        "Based on EDA and clustering, we recommend the following retention strategies for employees at risk of leaving:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature importance (for tree-based best model) to target interventions\n",
        "if hasattr(best_model, 'feature_importances_'):\n",
        "    imp = pd.DataFrame({'feature': feature_cols, 'importance': best_model.feature_importances_})\n",
        "    imp = imp.sort_values('importance', ascending=False)\n",
        "    imp.plot(x='feature', y='importance', kind='barh', legend=False, figsize=(8, 4))\n",
        "    plt.title('Feature importance (best model) for retention targeting')\n",
        "    plt.xlabel('Importance')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    print(imp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\"\"\n",
        "RETENTION STRATEGIES (Targeted by risk factors):\n",
        "\n",
        "1. LOW SATISFACTION: Conduct stay interviews and pulse surveys; address workload, recognition, and work-life balance.\n",
        "2. HIGH TENURE + BURNOUT: Offer sabbaticals, role rotation, or project variety; review promotion and growth paths.\n",
        "3. HIGH HOURS / OVERLOAD: Cap overtime, redistribute projects, and hire to reduce average_montly_hours.\n",
        "4. LOW SALARY (vs market): Benchmark compensation; consider raises or bonuses for high performers.\n",
        "5. NO PROMOTION (promotion_last_5years=0): Clear career ladder and internal mobility programs.\n",
        "6. DEPARTMENT-SPECIFIC: Tailor interventions by sales/technical/support (e.g., sales: quotas and incentives; technical: learning budget).\n",
        "\n",
        "Using the model: Score current employees; target retention efforts on those predicted as 'left' with highest probability.\n",
        "\"\"\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
