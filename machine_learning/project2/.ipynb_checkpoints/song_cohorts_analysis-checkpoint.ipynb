{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Creating Cohorts of Songs – Course-end Project 2\n",
        "**Simplilearn AI & ML PGP | Spotify Rolling Stones Dataset**\n",
        "\n",
        "**Objective:** Perform exploratory data analysis and cluster analysis to create cohorts of songs and understand the factors that define each cohort for better song recommendations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "%matplotlib inline\n",
        "sns.set_style('whitegrid')\n",
        "print(\"Libraries loaded successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load Data & Data Dictionary\n",
        "Load the Rolling Stones Spotify dataset and (optionally) the data dictionary for column definitions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load dataset\n",
        "df = pd.read_csv('rolling_stones_spotify.csv')\n",
        "# Remove unnamed index column if present\n",
        "if df.columns[0].startswith('Unnamed') or df.columns[0] == '':\n",
        "    df = df.iloc[:, 1:]\n",
        "print(\"Dataset shape:\", df.shape)\n",
        "print(\"\\nColumns:\", list(df.columns))\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load and display Data Dictionary (column definitions)\n",
        "try:\n",
        "    data_dict = pd.read_excel('Data Dictionary - Creating cohorts of songs.xlsx')\n",
        "    print(\"Data Dictionary - Creating cohorts of songs:\")\n",
        "    display(data_dict)\n",
        "except Exception as e:\n",
        "    print(\"Data dictionary not loaded:\", e)\n",
        "    print(\"Spotify audio features: acousticness, danceability, energy, instrumentalness,\")\n",
        "    print(\"liveness, loudness, speechiness, tempo, valence, popularity, duration_ms\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Data Quality Checks\n",
        "Check for missing values and basic statistics of numeric features used for clustering."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data quality - missing values\n",
        "print(\"Missing values per column:\")\n",
        "print(df.isnull().sum())\n",
        "print(\"\\nTotal missing:\", df.isnull().sum().sum())\n",
        "print(\"\\nData types:\\n\", df.dtypes)\n",
        "# Numeric features (Spotify audio features) for clustering\n",
        "feature_cols = ['acousticness', 'danceability', 'energy', 'instrumentalness', 'liveness',\n",
        "               'loudness', 'speechiness', 'tempo', 'valence', 'popularity', 'duration_ms']\n",
        "df_numeric = df[feature_cols].copy()\n",
        "print(\"\\nBasic statistics of clustering features:\")\n",
        "df_numeric.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Exploratory Data Analysis\n",
        "Understand distributions and relationships among audio features that will define song cohorts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Correlation heatmap of numeric features\n",
        "plt.figure(figsize=(10, 8))\n",
        "corr = df_numeric.corr()\n",
        "sns.heatmap(corr, annot=True, fmt='.2f', cmap='coolwarm', center=0)\n",
        "plt.title('Correlation between song audio features')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Distributions of key features\n",
        "fig, axes = plt.subplots(3, 4, figsize=(14, 10))\n",
        "axes = axes.flatten()\n",
        "for i, col in enumerate(feature_cols):\n",
        "    axes[i].hist(df_numeric[col].dropna(), bins=40, edgecolor='black', alpha=0.7)\n",
        "    axes[i].set_title(col)\n",
        "    axes[i].set_ylabel('Count')\n",
        "axes[-1].axis('off')\n",
        "plt.suptitle('Distribution of song features', y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pairplot of a subset of features (sample for speed)\n",
        "sample = df_numeric.sample(min(400, len(df_numeric)), random_state=42)\n",
        "sns.pairplot(sample[['energy', 'danceability', 'acousticness', 'valence', 'popularity']], diag_kind='kde')\n",
        "plt.suptitle('Pairwise relationships (sample)', y=1.02)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Cluster Analysis – Creating Cohorts of Songs\n",
        "Scale features and apply K-Means. Use elbow method and silhouette score to choose number of cohorts (k)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Handle any missing values and scale features\n",
        "X = df_numeric.dropna()\n",
        "if len(X) < len(df_numeric):\n",
        "    print(\"Dropped rows with missing values:\", len(df_numeric) - len(X))\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "print(\"Scaled feature matrix shape:\", X_scaled.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Elbow method and silhouette score for optimal k\n",
        "inertias = []\n",
        "silhouettes = []\n",
        "K_range = range(2, 12)\n",
        "for k in K_range:\n",
        "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
        "    kmeans.fit(X_scaled)\n",
        "    inertias.append(kmeans.inertia_)\n",
        "    silhouettes.append(silhouette_score(X_scaled, kmeans.labels_))\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
        "axes[0].plot(K_range, inertias, 'bo-')\n",
        "axes[0].set_xlabel('Number of clusters (k)')\n",
        "axes[0].set_ylabel('Inertia')\n",
        "axes[0].set_title('Elbow method')\n",
        "axes[1].plot(K_range, silhouettes, 'go-')\n",
        "axes[1].set_xlabel('Number of clusters (k)')\n",
        "axes[1].set_ylabel('Silhouette score')\n",
        "axes[1].set_title('Silhouette score')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "print(\"Silhouette scores:\", dict(zip(K_range, [round(s, 3) for s in silhouettes])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fit final K-Means with chosen k (e.g. k=5 for interpretable cohorts; adjust based on elbow/silhouette)\n",
        "n_clusters = 5\n",
        "kmeans_final = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
        "cluster_labels = kmeans_final.fit_predict(X_scaled)\n",
        "# Attach cluster to dataframe for interpretation\n",
        "df_clustered = X.copy()\n",
        "df_clustered['cohort'] = cluster_labels\n",
        "print(\"Cohort (cluster) sizes:\")\n",
        "print(df_clustered['cohort'].value_counts().sort_index())\n",
        "print(\"\\nSilhouette score for k=%d:\" % n_clusters, round(silhouette_score(X_scaled, cluster_labels), 3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Cohort Profiles – Factors That Define Each Cohort\n",
        "Compare mean feature values across cohorts to interpret what type of songs each cohort represents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cohort profiles (mean of each feature per cohort)\n",
        "cohort_profiles = df_clustered.groupby('cohort')[feature_cols].mean()\n",
        "cohort_profiles.round(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize cohort profiles (radar/bar)\n",
        "cohort_profiles_plot = cohort_profiles.copy()\n",
        "# Normalize for comparison (0-1 scale per feature for display)\n",
        "for c in cohort_profiles_plot.columns:\n",
        "    min_v, max_v = cohort_profiles_plot[c].min(), cohort_profiles_plot[c].max()\n",
        "    if max_v > min_v:\n",
        "        cohort_profiles_plot[c] = (cohort_profiles_plot[c] - min_v) / (max_v - min_v)\n",
        "cohort_profiles_plot.plot(kind='bar', figsize=(12, 5))\n",
        "plt.title('Cohort profiles (normalized feature means)')\n",
        "plt.xlabel('Cohort')\n",
        "plt.ylabel('Normalized value')\n",
        "plt.legend(bbox_to_anchor=(1.02, 1), loc='upper left')\n",
        "plt.xticks(rotation=0)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2D visualization: project cohorts by two important features (e.g. energy vs acousticness)\n",
        "df_clustered['cohort'] = cluster_labels\n",
        "plt.figure(figsize=(8, 6))\n",
        "for i in range(n_clusters):\n",
        "    subset = df_clustered[df_clustered['cohort'] == i]\n",
        "    plt.scatter(subset['energy'], subset['acousticness'], label=f'Cohort {i}', alpha=0.6)\n",
        "plt.xlabel('Energy')\n",
        "plt.ylabel('Acousticness')\n",
        "plt.title('Song cohorts in Energy–Acousticness space')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Summary – Factors That Create Cohorts of Songs\n",
        "Based on EDA and cluster analysis:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Summary: key differentiators per cohort (top 3 features above/below overall mean)\n",
        "overall_mean = df_clustered[feature_cols].mean()\n",
        "print(\"Factors that create distinct song cohorts (vs overall mean):\\n\")\n",
        "for cohort_id in range(n_clusters):\n",
        "    cohort_mean = cohort_profiles.loc[cohort_id]\n",
        "    diff = (cohort_mean - overall_mean).reindex(cohort_mean.index)\n",
        "    diff = diff.reindex(diff.abs().sort_values(ascending=False).index)\n",
        "    top = diff.head(3)\n",
        "    print(\"Cohort %d: \" % cohort_id, \" | \".join([\"%s=%.2f\" % (k, v) for k, v in top.items()]))\n",
        "print(\"\\nInterpretation: Cohorts are driven by energy, acousticness, danceability, valence,\")\n",
        "print(\"instrumentalness, tempo, and popularity. Use these profiles to recommend similar songs within each cohort.\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
